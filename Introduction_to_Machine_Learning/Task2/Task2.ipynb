{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load the date from disk and extract the pid for the test set\n",
    "df_X_train = pd.read_csv(\"train_features.csv\")\n",
    "df_y_train = pd.read_csv(\"train_labels.csv\")\n",
    "df_X_test = pd.read_csv(\"test_features.csv\")\n",
    "pid = df_X_test.pid.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with NaN and strange time values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all times s.t. they start at 1 and end with 12\n",
    "def normalizeTime(row, dict):\n",
    "    return int(row.Time) - dict[row.pid]\n",
    "\n",
    "dict_tr = (df_X_train['Time'].groupby(df_X_train.pid).max()-12).to_dict()\n",
    "dict_te = (df_X_test['Time'].groupby(df_X_test.pid).max()-12).to_dict()\n",
    "\n",
    "\n",
    "df_X_train['Time'] = df_X_train.apply(lambda row: normalizeTime(row, dict_tr), axis=1)\n",
    "df_X_test['Time'] = df_X_test.apply(lambda row: normalizeTime(row, dict_te), axis=1)\n",
    "\n",
    "# For verification only\n",
    "# df_X_train.groupby('Time').Time.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0   1   2   3   4   5   6   7   8   9   ...  23  24  25  26  27  28  \\\n",
      "0      12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "1      12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "2      12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "3      12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "4      12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
      "12659  12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "12660  12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "12661  12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "12662  12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "12663  12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "\n",
      "       29  30  31  32  \n",
      "0      12  12  12  12  \n",
      "1      12  12  12  12  \n",
      "2      12  12  12  12  \n",
      "3      12  12  12  12  \n",
      "4      12  12  12  12  \n",
      "...    ..  ..  ..  ..  \n",
      "12659  12  12  12  12  \n",
      "12660  12  12  12  12  \n",
      "12661  12  12  12  12  \n",
      "12662  12  12  12  12  \n",
      "12663  12  12  12  12  \n",
      "\n",
      "[12664 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Introduce a binary label (0 or 1) for every collumn that marks if the value was NaN or not\n",
    "df_X_train_mask = (~df_X_train.iloc[:,3:].isna()).astype(int)\n",
    "df_X_test_mask = (~df_X_test.iloc[:,3:].isna()).astype(int)\n",
    "\n",
    "\n",
    "def collapseMask(mask):\n",
    "    mask = np.reshape(mask.values, (-1, 12, mask.shape[1]))\n",
    "    mask = np.sum(mask, axis=1)\n",
    "    return pd.DataFrame(mask)\n",
    "\n",
    "# sum up per patient\n",
    "df_X_train_cmask = collapseMask(df_X_train_mask)\n",
    "df_X_test_cmask = collapseMask(df_X_test_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all NaN values with the mean of the other values of the correspondig catetgory of the patient\n",
    "# If no values are present for the coresspondig patient the median of all patients is taken\n",
    "def fillNaN(series, medians):\n",
    "    m = medians[series.name] if np.isnan(series.mean()) else series.mean()\n",
    "    return series.fillna(m)\n",
    "\n",
    "median_X_train = df_X_train.median()\n",
    "median_X_test = df_X_test.median()\n",
    "\n",
    "df_X_train = df_X_train.groupby(\"pid\").transform(lambda x: fillNaN(x, median_X_train))\n",
    "df_X_test = df_X_test.groupby(\"pid\").transform(lambda x: fillNaN(x, median_X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data s.t. we only have one row per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenates all 12 rows of a patient into one row (throwing away the pid and keeping the age only once)\n",
    "\n",
    "def transformDf(df):\n",
    "    frames = [df[df.Time == 1].reset_index()['Age']]\n",
    "    for i in range(1, 13):\n",
    "        frames.append(df[df.Time == i].reset_index().iloc[:,3:]) # reset_index() introduces a new collumn\n",
    "    return pd.concat(frames, axis=1)\n",
    "\n",
    "df_X_train_con = transformDf(df_X_train)\n",
    "df_X_test_con = transformDf(df_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative approach were we take the mean for every patient instead of keeping every feature\n",
    "def transformDfMean(df):\n",
    "    age = df[df.Time == 1].reset_index()['Age']\n",
    "    avg_df = df[df.Time == 1].reset_index().iloc[:,3:]\n",
    "    \n",
    "    for i in range(2, 13):\n",
    "        avg_df = avg_df + df[df.Time == i].reset_index().iloc[:,3:] # reset_index() introduces a new collumn\n",
    "    return pd.concat([age, avg_df/12], axis=1)\n",
    "\n",
    "df_X_train_mean = transformDfMean(df_X_train)\n",
    "df_X_test_mean = transformDfMean(df_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0   1   2   3   4   5   6   7   8   9   ...  23  24  25  26  27  28  \\\n",
      "0      12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "1      12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "2      12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "3      12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "4      12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
      "18990  12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "18991  12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "18992  12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "18993  12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "18994  12  12  12  12  12  12  12  12  12  12  ...  12  12  12  12  12  12   \n",
      "\n",
      "       29  30  31  32  \n",
      "0      12  12  12  12  \n",
      "1      12  12  12  12  \n",
      "2      12  12  12  12  \n",
      "3      12  12  12  12  \n",
      "4      12  12  12  12  \n",
      "...    ..  ..  ..  ..  \n",
      "18990  12  12  12  12  \n",
      "18991  12  12  12  12  \n",
      "18992  12  12  12  12  \n",
      "18993  12  12  12  12  \n",
      "18994  12  12  12  12  \n",
      "\n",
      "[18995 rows x 33 columns]\n",
      "        Age      EtCO2    PTT   BUN  Lactate       Temp        Hgb       HCO3  \\\n",
      "0      34.0  33.000000  32.20  12.0    2.100  36.750000   8.566667  25.333333   \n",
      "1      71.0  33.000000  27.80  12.0    2.100  36.000000  14.600000  23.900000   \n",
      "2      68.0  33.000000  20.90  21.0    2.100  36.250000  12.500000  27.000000   \n",
      "3      79.0  31.863636  32.20  22.0    3.855  36.818182   9.200000  23.900000   \n",
      "4      76.0  33.000000  28.55  22.0    2.100  36.750000  10.700000  25.500000   \n",
      "...     ...        ...    ...   ...      ...        ...        ...        ...   \n",
      "18990  80.0  33.000000  32.20  13.5    2.100  35.750000   8.350000  23.900000   \n",
      "18991  73.0  33.000000  55.50  50.0    2.100  36.000000  11.200000  29.000000   \n",
      "18992  53.0  33.000000  32.20  17.0    2.100  37.400000  10.800000  23.900000   \n",
      "18993  89.0  33.000000  34.70  13.0    2.100  36.636364   8.400000  23.900000   \n",
      "18994  85.0  33.000000  36.40  30.0    2.100  36.000000   9.450000  25.000000   \n",
      "\n",
      "       BaseExcess      RRate  ...  23  24  25  26  27  28  29  30  31  32  \n",
      "0       -0.666667  17.000000  ...  12  12  12  12  12  12  12  12  12  12  \n",
      "1       -1.000000  18.090909  ...  12  12  12  12  12  12  12  12  12  12  \n",
      "2       -1.000000  14.833333  ...  12  12  12  12  12  12  12  12  12  12  \n",
      "3       -1.000000  12.000000  ...  12  12  12  12  12  12  12  12  12  12  \n",
      "4        1.500000  12.090909  ...  12  12  12  12  12  12  12  12  12  12  \n",
      "...           ...        ...  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
      "18990   -1.000000  19.125000  ...  12  12  12  12  12  12  12  12  12  12  \n",
      "18991   -1.000000  19.545455  ...  12  12  12  12  12  12  12  12  12  12  \n",
      "18992    0.000000  16.500000  ...  12  12  12  12  12  12  12  12  12  12  \n",
      "18993   -1.000000  20.454545  ...  12  12  12  12  12  12  12  12  12  12  \n",
      "18994   -1.000000  18.272727  ...  12  12  12  12  12  12  12  12  12  12  \n",
      "\n",
      "[18995 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the mask with the other frames\n",
    "dfc_X_train = pd.concat([df_X_train_con, df_X_train_cmask], axis = 1)\n",
    "dfc_X_test = pd.concat([df_X_test_con, df_X_test_cmask], axis = 1)\n",
    "\n",
    "dfm_X_train = pd.concat([df_X_train_mean, df_X_train_cmask], axis = 1)\n",
    "dfm_X_test = pd.concat([df_X_test_mean, df_X_test_cmask], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "y = df_y_train.iloc[:, 1:11].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfm_X_train, y, test_size=0.01, random_state=42)\n",
    "\n",
    "rfc1 = RandomForestClassifier(n_estimators = 1000, n_jobs = -1,verbose = 1, warm_start = True)\n",
    "model = MultiOutputClassifier(estimator=rfc1, n_jobs=-1) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = model.predict_proba(dfm_X_test)\n",
    "\n",
    "# turn the output into a 2d array (originally for each parameter an 2d array is returned in a list wich contains for every entry\n",
    "# the proabability p and 1-p)\n",
    "y_pred1 = np.dstack(y_pred1)[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 Model Score: 1.0\n",
      "Task 1 Score: 0.8491862523669071\n"
     ]
    }
   ],
   "source": [
    "# Check performance with test set\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_test_pred = np.dstack(model.predict_proba(X_test))[:,1,:]\n",
    "print(\"Task 1 Model Score: \" + str(model.score(X_train, y_train)))\n",
    "print(f\"Task 1 Score: {np.mean([roc_auc_score(y_test[:,i], y_test_pred[:,i]) for i in range(0, 10)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.7s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "y = df_y_train.iloc[:, 11]\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfm_X_train, y, test_size=0.01, random_state=42)\n",
    "\n",
    "rfc2 = RandomForestClassifier(n_estimators=1000,n_jobs = -1,verbose = 1,warm_start = True)\n",
    "rfc2.fit(X_train, y_train)\n",
    "y_pred2 = rfc2.predict_proba(dfm_X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 Model Score: 1.0\n",
      "Task 2 Score: 0.7092115534738485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Check performance with test set\n",
    "print(\"Task 2 Model Score: \" + str(rfc2.score(X_train, y_train)))\n",
    "print(f\"Task 2 Score: {roc_auc_score(y_test, rfc2.predict_proba(X_test)[:,1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "y = df_y_train.iloc[:, 12:].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfc_X_train, y, test_size=0.01, random_state=42)\n",
    "regr = MultiOutputRegressor(RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1, 10]), n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "y_pred3 = regr.predict(dfc_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3 Model Score: 0.5578456447200713\n",
      "Task 3 Score: 0.7682390926247677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Check performance with test set\n",
    "y_test_pred = regr.predict(X_test)\n",
    "print(\"Task 3 Model Score: \" + str(regr.score(X_train, y_train)))\n",
    "print(f\"Task 3 Score: {np.mean([0.5 + 0.5 * np.maximum(0, r2_score(y_test[:,i], y_test_pred[:,i])) for i in range(0,4)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concantenates all predicitions and adds back the pid collumn\n",
    "sol = pd.DataFrame(np.concatenate((pid[:,None], y_pred1, y_pred2[:,None], y_pred3), axis=1))\n",
    "sol.set_axis(df_y_train.axes[1].to_list(), axis = 1, inplace=True)\n",
    "\n",
    "sol.to_csv('prediction.zip', index=False, compression=dict(method='zip', archive_name='prediction.csv'))\n",
    "sol.to_csv('pred_rounded.zip', index=False, float_format='%.3f', compression=dict(method='zip', archive_name='prediction.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "      <th>LABEL_Sepsis</th>\n",
       "      <th>LABEL_RRate</th>\n",
       "      <th>LABEL_ABPm</th>\n",
       "      <th>LABEL_SpO2</th>\n",
       "      <th>LABEL_Heartrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "      <td>12664.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15889.250000</td>\n",
       "      <td>0.279098</td>\n",
       "      <td>0.153652</td>\n",
       "      <td>0.255924</td>\n",
       "      <td>0.252783</td>\n",
       "      <td>0.255774</td>\n",
       "      <td>0.220658</td>\n",
       "      <td>0.238171</td>\n",
       "      <td>0.250764</td>\n",
       "      <td>0.039782</td>\n",
       "      <td>0.072580</td>\n",
       "      <td>0.076175</td>\n",
       "      <td>18.826886</td>\n",
       "      <td>82.406274</td>\n",
       "      <td>96.968422</td>\n",
       "      <td>84.174583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9120.097064</td>\n",
       "      <td>0.298752</td>\n",
       "      <td>0.104997</td>\n",
       "      <td>0.167785</td>\n",
       "      <td>0.168773</td>\n",
       "      <td>0.168119</td>\n",
       "      <td>0.183982</td>\n",
       "      <td>0.132997</td>\n",
       "      <td>0.217872</td>\n",
       "      <td>0.064512</td>\n",
       "      <td>0.161095</td>\n",
       "      <td>0.063285</td>\n",
       "      <td>2.392175</td>\n",
       "      <td>10.190763</td>\n",
       "      <td>1.340477</td>\n",
       "      <td>12.122225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.863635</td>\n",
       "      <td>43.451825</td>\n",
       "      <td>73.612398</td>\n",
       "      <td>41.117931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7993.000000</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>17.290126</td>\n",
       "      <td>75.071765</td>\n",
       "      <td>96.206004</td>\n",
       "      <td>75.526379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15983.000000</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.163500</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>18.566209</td>\n",
       "      <td>81.104275</td>\n",
       "      <td>97.149270</td>\n",
       "      <td>83.524809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23773.750000</td>\n",
       "      <td>0.543000</td>\n",
       "      <td>0.172000</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>0.341250</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.099250</td>\n",
       "      <td>20.097399</td>\n",
       "      <td>88.466940</td>\n",
       "      <td>97.944210</td>\n",
       "      <td>91.847775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31655.000000</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>0.487000</td>\n",
       "      <td>34.418600</td>\n",
       "      <td>131.928992</td>\n",
       "      <td>103.783469</td>\n",
       "      <td>151.960514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pid  LABEL_BaseExcess  LABEL_Fibrinogen     LABEL_AST  \\\n",
       "count  12664.000000      12664.000000      12664.000000  12664.000000   \n",
       "mean   15889.250000          0.279098          0.153652      0.255924   \n",
       "std     9120.097064          0.298752          0.104997      0.167785   \n",
       "min        0.000000          0.009000          0.011000      0.010000   \n",
       "25%     7993.000000          0.044000          0.100000      0.129000   \n",
       "50%    15983.000000          0.104000          0.135000      0.223000   \n",
       "75%    23773.750000          0.543000          0.172000      0.344000   \n",
       "max    31655.000000          0.973000          0.931000      0.957000   \n",
       "\n",
       "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
       "count        12664.000000           12664.000000   12664.000000   \n",
       "mean             0.252783               0.255774       0.220658   \n",
       "std              0.168773               0.168119       0.183982   \n",
       "min              0.007000               0.008000       0.014000   \n",
       "25%              0.125000               0.129000       0.083000   \n",
       "50%              0.220000               0.223000       0.156000   \n",
       "75%              0.341250               0.342000       0.306000   \n",
       "max              0.962000               0.973000       0.963000   \n",
       "\n",
       "       LABEL_TroponinI    LABEL_SaO2  LABEL_Bilirubin_direct   LABEL_EtCO2  \\\n",
       "count     12664.000000  12664.000000            12664.000000  12664.000000   \n",
       "mean          0.238171      0.250764                0.039782      0.072580   \n",
       "std           0.132997      0.217872                0.064512      0.161095   \n",
       "min           0.057000      0.016000                0.000000      0.000000   \n",
       "25%           0.136000      0.088000                0.009000      0.004000   \n",
       "50%           0.204000      0.163500                0.021000      0.018000   \n",
       "75%           0.303000      0.348000                0.045000      0.060000   \n",
       "max           0.798000      0.978000                0.798000      0.911000   \n",
       "\n",
       "       LABEL_Sepsis   LABEL_RRate    LABEL_ABPm    LABEL_SpO2  LABEL_Heartrate  \n",
       "count  12664.000000  12664.000000  12664.000000  12664.000000     12664.000000  \n",
       "mean       0.076175     18.826886     82.406274     96.968422        84.174583  \n",
       "std        0.063285      2.392175     10.190763      1.340477        12.122225  \n",
       "min        0.000000      8.863635     43.451825     73.612398        41.117931  \n",
       "25%        0.032000     17.290126     75.071765     96.206004        75.526379  \n",
       "50%        0.056000     18.566209     81.104275     97.149270        83.524809  \n",
       "75%        0.099250     20.097399     88.466940     97.944210        91.847775  \n",
       "max        0.487000     34.418600    131.928992    103.783469       151.960514  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count   mean  std    min    25%    50%    75%    max\n",
      "Age                                                         \n",
      "16.0     48.0   16.0  0.0   16.0   16.0   16.0   16.0   16.0\n",
      "17.0     24.0   17.0  0.0   17.0   17.0   17.0   17.0   17.0\n",
      "18.0    132.0   18.0  0.0   18.0   18.0   18.0   18.0   18.0\n",
      "19.0    384.0   19.0  0.0   19.0   19.0   19.0   19.0   19.0\n",
      "20.0    516.0   20.0  0.0   20.0   20.0   20.0   20.0   20.0\n",
      "21.0    696.0   21.0  0.0   21.0   21.0   21.0   21.0   21.0\n",
      "22.0    636.0   22.0  0.0   22.0   22.0   22.0   22.0   22.0\n",
      "23.0    708.0   23.0  0.0   23.0   23.0   23.0   23.0   23.0\n",
      "24.0    432.0   24.0  0.0   24.0   24.0   24.0   24.0   24.0\n",
      "25.0    612.0   25.0  0.0   25.0   25.0   25.0   25.0   25.0\n",
      "26.0    708.0   26.0  0.0   26.0   26.0   26.0   26.0   26.0\n",
      "27.0    504.0   27.0  0.0   27.0   27.0   27.0   27.0   27.0\n",
      "28.0    564.0   28.0  0.0   28.0   28.0   28.0   28.0   28.0\n",
      "29.0    624.0   29.0  0.0   29.0   29.0   29.0   29.0   29.0\n",
      "30.0    744.0   30.0  0.0   30.0   30.0   30.0   30.0   30.0\n",
      "31.0    576.0   31.0  0.0   31.0   31.0   31.0   31.0   31.0\n",
      "32.0    636.0   32.0  0.0   32.0   32.0   32.0   32.0   32.0\n",
      "33.0    876.0   33.0  0.0   33.0   33.0   33.0   33.0   33.0\n",
      "34.0    804.0   34.0  0.0   34.0   34.0   34.0   34.0   34.0\n",
      "35.0    828.0   35.0  0.0   35.0   35.0   35.0   35.0   35.0\n",
      "36.0    924.0   36.0  0.0   36.0   36.0   36.0   36.0   36.0\n",
      "37.0    936.0   37.0  0.0   37.0   37.0   37.0   37.0   37.0\n",
      "38.0   1020.0   38.0  0.0   38.0   38.0   38.0   38.0   38.0\n",
      "39.0   1152.0   39.0  0.0   39.0   39.0   39.0   39.0   39.0\n",
      "40.0   1248.0   40.0  0.0   40.0   40.0   40.0   40.0   40.0\n",
      "41.0   1380.0   41.0  0.0   41.0   41.0   41.0   41.0   41.0\n",
      "42.0   1404.0   42.0  0.0   42.0   42.0   42.0   42.0   42.0\n",
      "43.0   1560.0   43.0  0.0   43.0   43.0   43.0   43.0   43.0\n",
      "44.0   1500.0   44.0  0.0   44.0   44.0   44.0   44.0   44.0\n",
      "45.0   1992.0   45.0  0.0   45.0   45.0   45.0   45.0   45.0\n",
      "46.0   1908.0   46.0  0.0   46.0   46.0   46.0   46.0   46.0\n",
      "47.0   1992.0   47.0  0.0   47.0   47.0   47.0   47.0   47.0\n",
      "48.0   2268.0   48.0  0.0   48.0   48.0   48.0   48.0   48.0\n",
      "49.0   2316.0   49.0  0.0   49.0   49.0   49.0   49.0   49.0\n",
      "50.0   2316.0   50.0  0.0   50.0   50.0   50.0   50.0   50.0\n",
      "51.0   2400.0   51.0  0.0   51.0   51.0   51.0   51.0   51.0\n",
      "52.0   2676.0   52.0  0.0   52.0   52.0   52.0   52.0   52.0\n",
      "53.0   2832.0   53.0  0.0   53.0   53.0   53.0   53.0   53.0\n",
      "54.0   2856.0   54.0  0.0   54.0   54.0   54.0   54.0   54.0\n",
      "55.0   2568.0   55.0  0.0   55.0   55.0   55.0   55.0   55.0\n",
      "56.0   3060.0   56.0  0.0   56.0   56.0   56.0   56.0   56.0\n",
      "57.0   2976.0   57.0  0.0   57.0   57.0   57.0   57.0   57.0\n",
      "58.0   3300.0   58.0  0.0   58.0   58.0   58.0   58.0   58.0\n",
      "59.0   3288.0   59.0  0.0   59.0   59.0   59.0   59.0   59.0\n",
      "60.0   3336.0   60.0  0.0   60.0   60.0   60.0   60.0   60.0\n",
      "61.0   3744.0   61.0  0.0   61.0   61.0   61.0   61.0   61.0\n",
      "62.0   3240.0   62.0  0.0   62.0   62.0   62.0   62.0   62.0\n",
      "63.0   3060.0   63.0  0.0   63.0   63.0   63.0   63.0   63.0\n",
      "64.0   3168.0   64.0  0.0   64.0   64.0   64.0   64.0   64.0\n",
      "65.0   3816.0   65.0  0.0   65.0   65.0   65.0   65.0   65.0\n",
      "66.0   3900.0   66.0  0.0   66.0   66.0   66.0   66.0   66.0\n",
      "67.0   4128.0   67.0  0.0   67.0   67.0   67.0   67.0   67.0\n",
      "68.0   3780.0   68.0  0.0   68.0   68.0   68.0   68.0   68.0\n",
      "69.0   3588.0   69.0  0.0   69.0   69.0   69.0   69.0   69.0\n",
      "70.0   3540.0   70.0  0.0   70.0   70.0   70.0   70.0   70.0\n",
      "71.0   3876.0   71.0  0.0   71.0   71.0   71.0   71.0   71.0\n",
      "72.0   3708.0   72.0  0.0   72.0   72.0   72.0   72.0   72.0\n",
      "73.0   3576.0   73.0  0.0   73.0   73.0   73.0   73.0   73.0\n",
      "74.0   3132.0   74.0  0.0   74.0   74.0   74.0   74.0   74.0\n",
      "75.0   3300.0   75.0  0.0   75.0   75.0   75.0   75.0   75.0\n",
      "76.0   2940.0   76.0  0.0   76.0   76.0   76.0   76.0   76.0\n",
      "77.0   3408.0   77.0  0.0   77.0   77.0   77.0   77.0   77.0\n",
      "78.0   3228.0   78.0  0.0   78.0   78.0   78.0   78.0   78.0\n",
      "79.0   2700.0   79.0  0.0   79.0   79.0   79.0   79.0   79.0\n",
      "80.0   2736.0   80.0  0.0   80.0   80.0   80.0   80.0   80.0\n",
      "81.0   2496.0   81.0  0.0   81.0   81.0   81.0   81.0   81.0\n",
      "82.0   2652.0   82.0  0.0   82.0   82.0   82.0   82.0   82.0\n",
      "83.0   2436.0   83.0  0.0   83.0   83.0   83.0   83.0   83.0\n",
      "84.0   2448.0   84.0  0.0   84.0   84.0   84.0   84.0   84.0\n",
      "85.0   2052.0   85.0  0.0   85.0   85.0   85.0   85.0   85.0\n",
      "86.0   1788.0   86.0  0.0   86.0   86.0   86.0   86.0   86.0\n",
      "87.0   1620.0   87.0  0.0   87.0   87.0   87.0   87.0   87.0\n",
      "88.0   1236.0   88.0  0.0   88.0   88.0   88.0   88.0   88.0\n",
      "89.0    816.0   89.0  0.0   89.0   89.0   89.0   89.0   89.0\n",
      "100.0  1596.0  100.0  0.0  100.0  100.0  100.0  100.0  100.0\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df_X_test.groupby('Age').Age.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#NaN</th>\n",
       "      <th>Percent of not Nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EtCO2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUN</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lactate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hgb</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HCO3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaseExcess</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RRate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fibrinogen</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phosphate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBC</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creatinine</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaCO2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FiO2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platelets</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaO2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABPm</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Potassium</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABPd</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calcium</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alkalinephos</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpO2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bilirubin_direct</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chloride</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hct</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heartrate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bilirubin_total</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TroponinI</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABPs</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  #NaN  Percent of not Nan\n",
       "Time                 0                 0.0\n",
       "Age                  0                 0.0\n",
       "EtCO2                0                 0.0\n",
       "PTT                  0                 0.0\n",
       "BUN                  0                 0.0\n",
       "Lactate              0                 0.0\n",
       "Temp                 0                 0.0\n",
       "Hgb                  0                 0.0\n",
       "HCO3                 0                 0.0\n",
       "BaseExcess           0                 0.0\n",
       "RRate                0                 0.0\n",
       "Fibrinogen           0                 0.0\n",
       "Phosphate            0                 0.0\n",
       "WBC                  0                 0.0\n",
       "Creatinine           0                 0.0\n",
       "PaCO2                0                 0.0\n",
       "AST                  0                 0.0\n",
       "FiO2                 0                 0.0\n",
       "Platelets            0                 0.0\n",
       "SaO2                 0                 0.0\n",
       "Glucose              0                 0.0\n",
       "ABPm                 0                 0.0\n",
       "Magnesium            0                 0.0\n",
       "Potassium            0                 0.0\n",
       "ABPd                 0                 0.0\n",
       "Calcium              0                 0.0\n",
       "Alkalinephos         0                 0.0\n",
       "SpO2                 0                 0.0\n",
       "Bilirubin_direct     0                 0.0\n",
       "Chloride             0                 0.0\n",
       "Hct                  0                 0.0\n",
       "Heartrate            0                 0.0\n",
       "Bilirubin_total      0                 0.0\n",
       "TroponinI            0                 0.0\n",
       "ABPs                 0                 0.0\n",
       "pH                   0                 0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.DataFrame()\n",
    "t['#NaN'] = df_X_train.isna().sum().to_frame()\n",
    "t['Percent of not Nan'] = (df_X_train.isna().sum() / df_X_train.shape[0] * 100).to_frame()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'pid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24824/388387262.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# making sure that the pid can be safely dropped (has to be 0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mdf_X_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_X_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTime\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdf_y_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'pid'"
     ]
    }
   ],
   "source": [
    "# making sure that the pid can be safely dropped (has to be 0)\n",
    "(df_X_train.pid[df_X_train.Time == 1].values - df_y_train.pid.values).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7645019e57329b3c61af0000129ae91a700be83026cef3dd35ab543c8cbe108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
